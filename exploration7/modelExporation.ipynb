{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "import pickle\n",
    "from PIL import Image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "\n",
    "def carregar_pickle(nome_arquivo):\n",
    "  with open(nome_arquivo, 'rb') as arquivo:\n",
    "    objeto = pickle.load(arquivo)\n",
    "  return objeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2Test = keras.models.load_model('exp/bmw6/best_model_acc6_03.h5', custom_objects={\"f1_m\": f1_m , 'precision_m': precision_m,\n",
    "        'recall_m': recall_m })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_set = carregar_pickle('dataset_H3_W3S1.pkl')\n",
    "input_full = raw_data_set['inputs']\n",
    "output_full = raw_data_set['outputs']\n",
    "sequences_full = raw_data_set['sequences']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_grayscale_image(matrix, filename):\n",
    "    # Normaliza a matriz para o intervalo [0, 255]\n",
    "    normalized_matrix = (matrix - np.min(matrix)) * (255.0 / (np.max(matrix) - np.min(matrix)))\n",
    "    # Converte para tipo inteiro\n",
    "    grayscale_image = Image.fromarray(normalized_matrix.astype(np.uint8), mode='L')\n",
    "    grayscale_image.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFirstNElementsWithPredictAboveOrUnderPredict(inputFull, model, isAboveOrequal, predictValueRef, n):\n",
    "    sList = []\n",
    "    index = 0\n",
    "    while True:\n",
    "        v = model.predict(inputFull[0+index:1+index])[0][0]\n",
    "\n",
    "        print('v: ' + str(v))\n",
    "\n",
    "        if isAboveOrequal and v >= predictValueRef:\n",
    "            sList.append(index)\n",
    "        elif not isAboveOrequal and v < predictValueRef:\n",
    "            sList.append(index)\n",
    "\n",
    "        if len(sList) >= n:\n",
    "            break\n",
    "        \n",
    "        print('sList len: ' + str(len(sList)))\n",
    "        \n",
    "        index = index + 1\n",
    "\n",
    "    return sList\n",
    "\n",
    "def getInputFromInputFullAndIndex(inputFull, index):\n",
    "    return inputFull[0+index:1+index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 41ms/step\n",
      "v: 0.07839887\n",
      "sList len: 0\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "v: 0.003686926\n",
      "sList len: 0\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "v: 0.0062189577\n",
      "sList len: 0\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "v: 0.23412523\n",
      "sList len: 0\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "v: 0.8609274\n",
      "sList len: 0\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "v: 0.6608417\n",
      "sList len: 0\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "v: 0.049053676\n",
      "sList len: 0\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "v: 0.43479964\n",
      "sList len: 0\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "v: 0.9274257\n",
      "sList len: 0\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "v: 0.0030867956\n",
      "sList len: 0\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "v: 0.76205665\n",
      "sList len: 0\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "v: 0.98538387\n",
      "sList len: 1\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "v: 0.22126041\n",
      "sList len: 1\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "v: 0.14689714\n",
      "sList len: 1\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "v: 0.05253023\n",
      "sList len: 1\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "v: 0.026666936\n",
      "sList len: 1\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "v: 0.012009737\n",
      "sList len: 1\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "v: 0.057201598\n",
      "sList len: 1\n",
      "1/1 [==============================] - 0s 255ms/step\n",
      "v: 0.04404625\n",
      "sList len: 1\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "v: 0.9181235\n",
      "sList len: 1\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "v: 0.9858591\n",
      "sList len: 2\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "v: 0.9937513\n",
      "sList len: 3\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "v: 0.98972875\n",
      "sList len: 4\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "v: 0.9816857\n"
     ]
    }
   ],
   "source": [
    "goodList = getFirstNElementsWithPredictAboveOrUnderPredict(input_full, model2Test, True, 0.95, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 60ms/step\n",
      "v: 0.07839887\n",
      "sList len: 1\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "v: 0.003686926\n",
      "sList len: 2\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "v: 0.0062189577\n",
      "sList len: 3\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "v: 0.23412523\n",
      "sList len: 4\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "v: 0.8609274\n",
      "sList len: 4\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "v: 0.6608417\n",
      "sList len: 4\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "v: 0.049053676\n"
     ]
    }
   ],
   "source": [
    "badList = getFirstNElementsWithPredictAboveOrUnderPredict(input_full, model2Test, False, 0.5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11, 20, 21, 22, 23]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goodList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = getInputFromInputFullAndIndex(input_full, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TCGTCAGTTCGTACACCATTGGTGCCAGTGACTGTGGTCAATTCGGTAGAAGTAGAGGTAAAAGTGCTGTTCCATGGCTCAGTTGTAGTTATGATGGTGCTAGCAGTTGTTGGAGTTCTGATGACAATGACGGTTTCGTCAGTTGGAACGCCGTTGGTACCGGTGACGGTGGTCATTTCAGTAGATGTAGAAGTGAAAGTACCGGTCCATGGTTCCGTTGTAGTTATGGTAGTACTGACAGTATAATTTGAAGGGTCTGGAATGGTACAGTTTGGCTGGCTTAGATTGTTGTCAAAAGTATATACGTACCCTTCAAAGTCATCACTAACGGTAGTGCCATCTGGTAGTGTCACACTAATTGGAAGTGTACCCCAGGCAACGGCATTTGAGTAAACAATCTTCATTGGATAATAGAAACCAGCATACATGTAGACAGTCCCTGTAATATTATCAGGGGGACTTCCATTCCATGGCTTGATACCATTGATGGTGAAGTTAGT']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = sequences_full[0+11:1+11]\n",
    "sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2Test.predict(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x2d483a3bfd0>,\n",
       " <keras.layers.convolutional.conv1d.Conv1D at 0x2d483a98250>,\n",
       " <keras.layers.pooling.average_pooling1d.AveragePooling1D at 0x2d483a98490>,\n",
       " <keras.layers.convolutional.conv1d.Conv1D at 0x2d483a989a0>,\n",
       " <keras.layers.pooling.average_pooling1d.AveragePooling1D at 0x2d483a98c40>,\n",
       " <keras.layers.convolutional.conv1d.Conv1D at 0x2d483a99150>,\n",
       " <keras.layers.pooling.global_average_pooling1d.GlobalAveragePooling1D at 0x2d483a993f0>,\n",
       " <keras.layers.reshaping.flatten.Flatten at 0x2d483a991b0>,\n",
       " <keras.layers.core.dense.Dense at 0x2d483a999c0>,\n",
       " <keras.layers.core.dense.Dense at 0x2d483a99c00>,\n",
       " <keras.layers.core.dense.Dense at 0x2d483a9a0b0>]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2Test.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_output = model2Test.layers[6].output\n",
    "get_output = keras.backend.function([model2Test.input], [intermediate_output])\n",
    "output = get_output([input])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_reshaped = output.reshape(output.shape[1], output.shape[2])\n",
    "output_reshaped = output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 60)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00809478, 0.0418728 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.09380104, 0.        ,\n",
       "        0.        , 0.02054345, 0.        , 0.0180725 , 0.        ,\n",
       "        0.1301553 , 0.        , 0.        , 0.        , 0.19605362,\n",
       "        0.00779951, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.19382474, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01706999, 0.        , 0.        ,\n",
       "        0.02224108, 0.        , 0.00826497, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.03742843,\n",
       "        0.        , 0.        , 0.10345274, 0.        , 0.        ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp/network_exploration/best_only6/goods\n",
    "save_grayscale_image(input.reshape(input.shape[1], input.shape[2]), 'exp/network_exploration/best_only6/goods/input_00.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
