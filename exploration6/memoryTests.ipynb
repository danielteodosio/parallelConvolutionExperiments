{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import os\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def carregar_pickle(nome_arquivo):\n",
    "  with open(nome_arquivo, 'rb') as arquivo:\n",
    "    objeto = pickle.load(arquivo)\n",
    "  return objeto\n",
    "\n",
    "\n",
    "def process_memory():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    mem_info = process.memory_info()\n",
    "    return mem_info.rss\n",
    "\n",
    "def profile(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "\n",
    "        mem_before = process_memory()\n",
    "        result = func(*args, **kwargs)\n",
    "        mem_after = process_memory()\n",
    "        print('function: '+ func.__name__ + ' | '+ 'memo after: ' + str(mem_after) \n",
    "              + ' | ' + 'memo before: ' + str(mem_before) + ' | '+ 'memo diff:' + str(mem_after - mem_before))\n",
    "\n",
    "        return result\n",
    "    return wrapper    \n",
    "\n",
    "@profile\n",
    "def trainning_function(input_train, output_train, input_validation, output_validation):\n",
    "\n",
    "    uniqueInput = keras.Input(shape=(497, 16)) \n",
    "\n",
    "    conv1R0 = keras.layers.Conv1D(10, kernel_size= 1, strides= 1, padding='same', activation='relu', input_shape = (497, 16), use_bias= True)(uniqueInput)\n",
    "    pool1R0 = keras.layers.AveragePooling1D(pool_size=11, strides= 3, padding='valid')(conv1R0)\n",
    "    conv2R0 = keras.layers.Conv1D(35, kernel_size= 1, strides= 1, padding='valid', activation='relu', input_shape = (163, 10), use_bias= True)(pool1R0)\n",
    "    pool2R0 = keras.layers.AveragePooling1D(pool_size=37, strides= 21, padding='valid')(conv2R0)\n",
    "    conv3R0 = keras.layers.Conv1D(60, kernel_size= 1, strides= 1, padding='valid', activation='relu', input_shape = (35, 7), use_bias= True)(pool2R0)\n",
    "    pool3R0 = keras.layers.GlobalAveragePooling1D()(conv3R0)\n",
    "    flat0 =  keras.layers.Flatten()(pool3R0)\n",
    "\n",
    "    conv1R1 = keras.layers.Conv1D(10, kernel_size= 3, strides= 1, padding='same', activation='relu', input_shape = (497, 16), use_bias= True)(uniqueInput)\n",
    "    pool1R1 = keras.layers.AveragePooling1D(pool_size=11, strides= 3, padding='valid')(conv1R1)\n",
    "    conv2R1 = keras.layers.Conv1D(35, kernel_size= 1, strides= 1, padding='valid', activation='relu', input_shape = (163, 10), use_bias= True)(pool1R1)\n",
    "    pool2R1 = keras.layers.AveragePooling1D(pool_size=37, strides= 21, padding='valid')(conv2R1)\n",
    "    conv3R1 = keras.layers.Conv1D(60, kernel_size= 1, strides= 1, padding='valid', activation='relu', input_shape = (35, 7), use_bias= True)(pool2R1)\n",
    "    pool3R1 = keras.layers.GlobalAveragePooling1D()(conv3R1)\n",
    "    flat1 =  keras.layers.Flatten()(pool3R1)\n",
    "\n",
    "    conv1R2 = keras.layers.Conv1D(10, kernel_size= 6, strides= 1, padding='same', activation='relu', input_shape = (497, 16), use_bias= True)(uniqueInput)\n",
    "    pool1R2 = keras.layers.AveragePooling1D(pool_size=11, strides= 3, padding='valid')(conv1R2)\n",
    "    conv2R2 = keras.layers.Conv1D(35, kernel_size= 1, strides= 1, padding='valid', activation='relu', input_shape = (163, 10), use_bias= True)(pool1R2)\n",
    "    pool2R2 = keras.layers.AveragePooling1D(pool_size=37, strides= 21, padding='valid')(conv2R2)\n",
    "    conv3R2 = keras.layers.Conv1D(60, kernel_size= 1, strides= 1, padding='valid', activation='relu', input_shape = (35, 7), use_bias= True)(pool2R2)\n",
    "    pool3R2 = keras.layers.GlobalAveragePooling1D()(conv3R2)\n",
    "    flat2 =  keras.layers.Flatten()(pool3R2)\n",
    "\n",
    "    conv1R3 = keras.layers.Conv1D(10, kernel_size= 9, strides= 1, padding='same', activation='relu', input_shape = (497, 16), use_bias= True)(uniqueInput)\n",
    "    pool1R3 = keras.layers.AveragePooling1D(pool_size=11, strides= 3, padding='valid')(conv1R3)\n",
    "    conv2R3 = keras.layers.Conv1D(35, kernel_size= 1, strides= 1, padding='valid', activation='relu', input_shape = (163, 10), use_bias= True)(pool1R3)\n",
    "    pool2R3 = keras.layers.AveragePooling1D(pool_size=37, strides= 21, padding='valid')(conv2R3)\n",
    "    conv3R3 = keras.layers.Conv1D(60, kernel_size= 1, strides= 1, padding='valid', activation='relu', input_shape = (35, 7), use_bias= True)(pool2R3)\n",
    "    pool3R3 = keras.layers.GlobalAveragePooling1D()(conv3R3)\n",
    "    flat3 =  keras.layers.Flatten()(pool3R3)\n",
    "\n",
    "    concatenated_filters = keras.layers.concatenate([flat0, flat1, flat2, flat3])\n",
    "\n",
    "\n",
    "    dense1 = keras.layers.Dense(100, activation=keras.layers.LeakyReLU(alpha=0.3))(concatenated_filters)  #keras.layers.LeakyReLU(alpha=0.3)\n",
    "    dense2 = keras.layers.Dense(32, activation=keras.layers.LeakyReLU(alpha=0.3))(dense1)\n",
    "    #dense3 = keras.layers.Dense(10, activation=keras.layers.LeakyReLU(alpha=0.3))(dense2)\n",
    "    outpu1 = keras.layers.Dense(1, activation='sigmoid')(dense2)\n",
    "\n",
    "    model = keras.Model(inputs= uniqueInput, outputs=outpu1)\n",
    "\n",
    "    model.compile(loss=keras.losses.BinaryCrossentropy(reduction='sum_over_batch_size'), \n",
    "              metrics=['accuracy']\n",
    "            , optimizer= keras.optimizers.Adam(learning_rate=0.001))\n",
    "    \n",
    "    model.fit(input_train, output_train, epochs= 15, batch_size = 32, \n",
    "                     validation_data=(input_validation, output_validation), shuffle= True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_set1 = carregar_pickle('dataset_H3_W3S1.pkl')\n",
    "input_full = raw_data_set1['inputs']\n",
    "output_full = raw_data_set1['outputs']\n",
    "sequences_full = raw_data_set1['sequences']\n",
    "\n",
    "input_train, input_tv, output_train, output_tv, sequence_train, sequence_tv = train_test_split(input_full, output_full, \n",
    "sequences_full, train_size=0.70 , shuffle= True, random_state = 121);\n",
    "\n",
    "input_validation, input_test, output_validation, output_test, sequence_validation, sequence_test = train_test_split(input_tv, output_tv, \n",
    "sequence_tv, train_size=0.5 , shuffle= False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "328/328 [==============================] - 58s 166ms/step - loss: 0.5510 - accuracy: 0.7110 - val_loss: 0.4603 - val_accuracy: 0.7901\n",
      "Epoch 2/15\n",
      "328/328 [==============================] - 51s 156ms/step - loss: 0.4633 - accuracy: 0.7902 - val_loss: 0.4449 - val_accuracy: 0.7946\n",
      "Epoch 3/15\n",
      "328/328 [==============================] - 51s 155ms/step - loss: 0.4358 - accuracy: 0.8062 - val_loss: 0.4092 - val_accuracy: 0.8160\n",
      "Epoch 4/15\n",
      "328/328 [==============================] - 51s 155ms/step - loss: 0.4348 - accuracy: 0.8060 - val_loss: 0.4052 - val_accuracy: 0.8347\n",
      "Epoch 5/15\n",
      "328/328 [==============================] - 50s 153ms/step - loss: 0.4075 - accuracy: 0.8233 - val_loss: 0.3919 - val_accuracy: 0.8329\n",
      "Epoch 6/15\n",
      "328/328 [==============================] - 56s 172ms/step - loss: 0.4061 - accuracy: 0.8260 - val_loss: 0.3822 - val_accuracy: 0.8396\n",
      "Epoch 7/15\n",
      "328/328 [==============================] - 51s 156ms/step - loss: 0.3971 - accuracy: 0.8259 - val_loss: 0.3861 - val_accuracy: 0.8405\n",
      "Epoch 8/15\n",
      "328/328 [==============================] - 52s 157ms/step - loss: 0.3867 - accuracy: 0.8341 - val_loss: 0.3728 - val_accuracy: 0.8427\n",
      "Epoch 9/15\n",
      "328/328 [==============================] - 51s 154ms/step - loss: 0.3815 - accuracy: 0.8388 - val_loss: 0.3869 - val_accuracy: 0.8369\n",
      "Epoch 10/15\n",
      "328/328 [==============================] - 54s 164ms/step - loss: 0.3886 - accuracy: 0.8329 - val_loss: 0.3746 - val_accuracy: 0.8422\n",
      "Epoch 11/15\n",
      "328/328 [==============================] - 55s 168ms/step - loss: 0.3798 - accuracy: 0.8403 - val_loss: 0.3637 - val_accuracy: 0.8485\n",
      "Epoch 12/15\n",
      "328/328 [==============================] - 64s 195ms/step - loss: 0.3757 - accuracy: 0.8402 - val_loss: 0.3691 - val_accuracy: 0.8503\n",
      "Epoch 13/15\n",
      "328/328 [==============================] - 52s 160ms/step - loss: 0.3639 - accuracy: 0.8452 - val_loss: 0.3610 - val_accuracy: 0.8494\n",
      "Epoch 14/15\n",
      "328/328 [==============================] - 54s 164ms/step - loss: 0.3699 - accuracy: 0.8405 - val_loss: 0.3509 - val_accuracy: 0.8547\n",
      "Epoch 15/15\n",
      "328/328 [==============================] - 54s 166ms/step - loss: 0.3696 - accuracy: 0.8419 - val_loss: 0.3532 - val_accuracy: 0.8556\n",
      "function: trainning_function | memo after: 3067441152 | memo before: 2545643520 | memo diff:521797632\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainning_function(input_train, output_train, input_validation, output_validation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
