{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import os\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def carregar_pickle(nome_arquivo):\n",
    "  with open(nome_arquivo, 'rb') as arquivo:\n",
    "    objeto = pickle.load(arquivo)\n",
    "  return objeto\n",
    "\n",
    "\n",
    "def process_memory():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    mem_info = process.memory_info()\n",
    "    return mem_info.rss\n",
    "\n",
    "def profile(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "\n",
    "        mem_before = process_memory()\n",
    "        result = func(*args, **kwargs)\n",
    "        mem_after = process_memory()\n",
    "        print('function: '+ func.__name__ + ' | '+ 'memo after: ' + str(mem_after) \n",
    "              + ' | ' + 'memo before: ' + str(mem_before) + ' | '+ 'memo diff:' + str(mem_after - mem_before))\n",
    "\n",
    "        return result\n",
    "    return wrapper    \n",
    "\n",
    "@profile\n",
    "def trainning_function(input_train, output_train, input_validation, output_validation):\n",
    "\n",
    "    uniqueInput = keras.Input(shape=(497, 16)) \n",
    "\n",
    "    conv1R0 = keras.layers.Conv1D(10, kernel_size= 1, strides= 1, padding='same', activation='relu', input_shape = (497, 16), use_bias= True)(uniqueInput)\n",
    "    pool1R0 = keras.layers.AveragePooling1D(pool_size=11, strides= 3, padding='valid')(conv1R0)\n",
    "    conv2R0 = keras.layers.Conv1D(35, kernel_size= 1, strides= 1, padding='valid', activation='relu', input_shape = (163, 10), use_bias= True)(pool1R0)\n",
    "    pool2R0 = keras.layers.AveragePooling1D(pool_size=37, strides= 21, padding='valid')(conv2R0)\n",
    "    conv3R0 = keras.layers.Conv1D(60, kernel_size= 1, strides= 1, padding='valid', activation='relu', input_shape = (35, 7), use_bias= True)(pool2R0)\n",
    "    pool3R0 = keras.layers.GlobalAveragePooling1D()(conv3R0)\n",
    "    flat0 =  keras.layers.Flatten()(pool3R0)\n",
    "\n",
    "    conv1R1 = keras.layers.Conv1D(10, kernel_size= 3, strides= 1, padding='same', activation='relu', input_shape = (497, 16), use_bias= True)(uniqueInput)\n",
    "    pool1R1 = keras.layers.AveragePooling1D(pool_size=11, strides= 3, padding='valid')(conv1R1)\n",
    "    conv2R1 = keras.layers.Conv1D(35, kernel_size= 1, strides= 1, padding='valid', activation='relu', input_shape = (163, 10), use_bias= True)(pool1R1)\n",
    "    pool2R1 = keras.layers.AveragePooling1D(pool_size=37, strides= 21, padding='valid')(conv2R1)\n",
    "    conv3R1 = keras.layers.Conv1D(60, kernel_size= 1, strides= 1, padding='valid', activation='relu', input_shape = (35, 7), use_bias= True)(pool2R1)\n",
    "    pool3R1 = keras.layers.GlobalAveragePooling1D()(conv3R1)\n",
    "    flat1 =  keras.layers.Flatten()(pool3R1)\n",
    "\n",
    "    conv1R2 = keras.layers.Conv1D(10, kernel_size= 6, strides= 1, padding='same', activation='relu', input_shape = (497, 16), use_bias= True)(uniqueInput)\n",
    "    pool1R2 = keras.layers.AveragePooling1D(pool_size=11, strides= 3, padding='valid')(conv1R2)\n",
    "    conv2R2 = keras.layers.Conv1D(35, kernel_size= 1, strides= 1, padding='valid', activation='relu', input_shape = (163, 10), use_bias= True)(pool1R2)\n",
    "    pool2R2 = keras.layers.AveragePooling1D(pool_size=37, strides= 21, padding='valid')(conv2R2)\n",
    "    conv3R2 = keras.layers.Conv1D(60, kernel_size= 1, strides= 1, padding='valid', activation='relu', input_shape = (35, 7), use_bias= True)(pool2R2)\n",
    "    pool3R2 = keras.layers.GlobalAveragePooling1D()(conv3R2)\n",
    "    flat2 =  keras.layers.Flatten()(pool3R2)\n",
    "\n",
    "    conv1R3 = keras.layers.Conv1D(10, kernel_size= 9, strides= 1, padding='same', activation='relu', input_shape = (497, 16), use_bias= True)(uniqueInput)\n",
    "    pool1R3 = keras.layers.AveragePooling1D(pool_size=11, strides= 3, padding='valid')(conv1R3)\n",
    "    conv2R3 = keras.layers.Conv1D(35, kernel_size= 1, strides= 1, padding='valid', activation='relu', input_shape = (163, 10), use_bias= True)(pool1R3)\n",
    "    pool2R3 = keras.layers.AveragePooling1D(pool_size=37, strides= 21, padding='valid')(conv2R3)\n",
    "    conv3R3 = keras.layers.Conv1D(60, kernel_size= 1, strides= 1, padding='valid', activation='relu', input_shape = (35, 7), use_bias= True)(pool2R3)\n",
    "    pool3R3 = keras.layers.GlobalAveragePooling1D()(conv3R3)\n",
    "    flat3 =  keras.layers.Flatten()(pool3R3)\n",
    "\n",
    "    concatenated_filters = keras.layers.concatenate([flat0, flat1, flat2, flat3])\n",
    "\n",
    "\n",
    "    dense1 = keras.layers.Dense(100, activation=keras.layers.LeakyReLU(alpha=0.3))(concatenated_filters)  #keras.layers.LeakyReLU(alpha=0.3)\n",
    "    dense2 = keras.layers.Dense(32, activation=keras.layers.LeakyReLU(alpha=0.3))(dense1)\n",
    "    #dense3 = keras.layers.Dense(10, activation=keras.layers.LeakyReLU(alpha=0.3))(dense2)\n",
    "    outpu1 = keras.layers.Dense(1, activation='sigmoid')(dense2)\n",
    "\n",
    "    model = keras.Model(inputs= uniqueInput, outputs=outpu1)\n",
    "\n",
    "    model.compile(loss=keras.losses.BinaryCrossentropy(reduction='sum_over_batch_size'), \n",
    "              metrics=['accuracy']\n",
    "            , optimizer= keras.optimizers.Adam(learning_rate=0.001))\n",
    "    \n",
    "    model.fit(input_train, output_train, epochs= 15, batch_size = 32, \n",
    "                     validation_data=(input_validation, output_validation), shuffle= True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_set1 = carregar_pickle('dataset_H3_W3S1.pkl')\n",
    "input_full = raw_data_set1['inputs']\n",
    "output_full = raw_data_set1['outputs']\n",
    "sequences_full = raw_data_set1['sequences']\n",
    "\n",
    "input_train, input_tv, output_train, output_tv, sequence_train, sequence_tv = train_test_split(input_full, output_full, \n",
    "sequences_full, train_size=0.70 , shuffle= True, random_state = 122);\n",
    "\n",
    "input_validation, input_test, output_validation, output_test, sequence_validation, sequence_test = train_test_split(input_tv, output_tv, \n",
    "sequence_tv, train_size=0.5 , shuffle= False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "328/328 [==============================] - 63s 176ms/step - loss: 0.5272 - accuracy: 0.7367 - val_loss: 0.4704 - val_accuracy: 0.7843\n",
      "Epoch 2/15\n",
      "328/328 [==============================] - 79s 241ms/step - loss: 0.4541 - accuracy: 0.7945 - val_loss: 0.4463 - val_accuracy: 0.8057\n",
      "Epoch 3/15\n",
      "328/328 [==============================] - 103s 314ms/step - loss: 0.4308 - accuracy: 0.8092 - val_loss: 0.4270 - val_accuracy: 0.8168\n",
      "Epoch 4/15\n",
      "328/328 [==============================] - 103s 314ms/step - loss: 0.4183 - accuracy: 0.8194 - val_loss: 0.4107 - val_accuracy: 0.8258\n",
      "Epoch 5/15\n",
      "328/328 [==============================] - 53s 162ms/step - loss: 0.4067 - accuracy: 0.8228 - val_loss: 0.3818 - val_accuracy: 0.8333\n",
      "Epoch 6/15\n",
      "328/328 [==============================] - 53s 161ms/step - loss: 0.3942 - accuracy: 0.8312 - val_loss: 0.3848 - val_accuracy: 0.8356\n",
      "Epoch 7/15\n",
      "328/328 [==============================] - 53s 161ms/step - loss: 0.3928 - accuracy: 0.8346 - val_loss: 0.3794 - val_accuracy: 0.8382\n",
      "Epoch 8/15\n",
      "328/328 [==============================] - 60s 183ms/step - loss: 0.3892 - accuracy: 0.8356 - val_loss: 0.3866 - val_accuracy: 0.8298\n",
      "Epoch 9/15\n",
      "328/328 [==============================] - 54s 166ms/step - loss: 0.3870 - accuracy: 0.8333 - val_loss: 0.4312 - val_accuracy: 0.8057\n",
      "Epoch 10/15\n",
      "328/328 [==============================] - 61s 185ms/step - loss: 0.3803 - accuracy: 0.8407 - val_loss: 0.3741 - val_accuracy: 0.8400\n",
      "Epoch 11/15\n",
      "328/328 [==============================] - 53s 161ms/step - loss: 0.3768 - accuracy: 0.8395 - val_loss: 0.3891 - val_accuracy: 0.8298\n",
      "Epoch 12/15\n",
      "328/328 [==============================] - 54s 164ms/step - loss: 0.3715 - accuracy: 0.8454 - val_loss: 0.3696 - val_accuracy: 0.8418\n",
      "Epoch 13/15\n",
      "328/328 [==============================] - 55s 168ms/step - loss: 0.3717 - accuracy: 0.8432 - val_loss: 0.3664 - val_accuracy: 0.8396\n",
      "Epoch 14/15\n",
      "328/328 [==============================] - 53s 160ms/step - loss: 0.3660 - accuracy: 0.8444 - val_loss: 0.4024 - val_accuracy: 0.8209\n",
      "Epoch 15/15\n",
      "328/328 [==============================] - 53s 161ms/step - loss: 0.3673 - accuracy: 0.8428 - val_loss: 0.4034 - val_accuracy: 0.8155\n",
      "function: trainning_function | memo after: 3068899328 | memo before: 2548502528 | memo diff:520396800\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainning_function(input_train, output_train, input_validation, output_validation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
